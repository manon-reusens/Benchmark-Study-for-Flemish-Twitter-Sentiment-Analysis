{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3495114f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from textblob_nl import PatternTagger, PatternAnalyzer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7cb6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annotations=  pd.read_csv('C:/Users/u0146965/OneDrive - KU Leuven/Sentiment analysis/full_cleaned_dataset.csv')\n",
    "df_annotations.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672d406a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=[]\n",
    "for i in tqdm(range(len(df_annotations['text']))):\n",
    "    blob = TextBlob(df_annotations['text'][i], pos_tagger=PatternTagger(), analyzer=PatternAnalyzer())\n",
    "    predictions.append(blob.sentiment[0])\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bac498c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(predictions)):\n",
    "    if predictions[i]< -0.5:\n",
    "        predictions[i]='NEGATIVE'\n",
    "    elif predictions[i]> 0.5:\n",
    "        predictions[i]='POSITIVE'\n",
    "    else:\n",
    "        predictions[i]='NEUTRAL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea64822",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#definieer de confusion matrix\n",
    "def cf_mat(y_test, y_pred):\n",
    "    #ax= plt.subplot()\n",
    "    mat=confusion_matrix(y_test, y_pred, labels= ['NEGATIVE', 'NEUTRAL', 'POSITIVE'])/len(y_test)\n",
    "    #ax.xaxis.set_ticklabels(['NEGATIVE', 'NEUTRAL', 'POSITIVE']); ax.yaxis.set_ticklabels(['POSITIVE', 'NEUTRAL','NEGATIVE' ]);\n",
    "    return sns.heatmap(mat, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17913f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "print(accuracy_score(df_annotations['label'], predictions))\n",
    "print(cf_mat(df_annotations['label'], predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c0fedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(predictions)):\n",
    "    predictions[i] = predictions[i].replace('NEUTRAL', '1')\n",
    "    predictions[i] = predictions[i].replace('POSITIVE', '2')\n",
    "    predictions[i] = predictions[i].replace('NEGATIVE', '0') \n",
    "for i in range(len(predictions)):\n",
    "    predictions[i]= int(predictions[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a43534",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a410bf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#zet de y-waarden goed\n",
    "y= df_annotations['label']\n",
    "y = y.replace('NEUTRAL','1')\n",
    "y = y.replace('POSITIVE','2')\n",
    "y = y.replace('NEGATIVE','0')\n",
    "for i in range(len(y)):\n",
    "    y[i]=int(y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ff2c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "new=[]\n",
    "for i in y:\n",
    "    new.append(int(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc0c7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "metrics.f1_score(new, predictions, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16d5e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.precision_score(new, predictions, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd8e3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.recall_score(new, predictions, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80a23d7",
   "metadata": {},
   "source": [
    "# Lemmatized approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55082be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=[]\n",
    "for i in tqdm(range(len(df_annotations['processed_annotations_lemmatized_joined']))):\n",
    "    if type(df_annotations['processed_annotations_lemmatized_joined'][i])== float:\n",
    "        df_annotations['processed_annotations_lemmatized_joined'][i]=''\n",
    "    blob = TextBlob(df_annotations['processed_annotations_lemmatized_joined'][i], pos_tagger=PatternTagger(), analyzer=PatternAnalyzer())\n",
    "    predictions.append(blob.sentiment[0])\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657014e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(predictions)):\n",
    "    if predictions[i]< -0.5:\n",
    "        predictions[i]='NEGATIVE'\n",
    "    elif predictions[i]> 0.5:\n",
    "        predictions[i]='POSITIVE'\n",
    "    else:\n",
    "        predictions[i]='NEUTRAL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bce0425",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#definieer de confusion matrix\n",
    "def cf_mat(y_test, y_pred):\n",
    "    #ax= plt.subplot()\n",
    "    mat=confusion_matrix(y_test, y_pred, labels= ['NEGATIVE', 'NEUTRAL', 'POSITIVE'])/len(y_test)\n",
    "    #ax.xaxis.set_ticklabels(['NEGATIVE', 'NEUTRAL', 'POSITIVE']); ax.yaxis.set_ticklabels(['POSITIVE', 'NEUTRAL','NEGATIVE' ]);\n",
    "    return sns.heatmap(mat, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8481e363",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "print(accuracy_score(df_annotations['label'], predictions))\n",
    "print(cf_mat(df_annotations['label'], predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a640a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(predictions)):\n",
    "    predictions[i] = predictions[i].replace('NEUTRAL', '1')\n",
    "    predictions[i] = predictions[i].replace('POSITIVE', '2')\n",
    "    predictions[i] = predictions[i].replace('NEGATIVE', '0') \n",
    "for i in range(len(predictions)):\n",
    "    predictions[i]= int(predictions[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9ed746",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6bb035",
   "metadata": {},
   "outputs": [],
   "source": [
    "#zet de y-waarden goed\n",
    "y= df_annotations['label']\n",
    "y = y.replace('NEUTRAL','1')\n",
    "y = y.replace('POSITIVE','2')\n",
    "y = y.replace('NEGATIVE','0')\n",
    "for i in range(len(y)):\n",
    "    y[i]=int(y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a11f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "new=[]\n",
    "for i in y:\n",
    "    new.append(int(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8505deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "metrics.f1_score(new, predictions, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd619c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.precision_score(new, predictions, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cf486b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.recall_score(new, predictions, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129c7312",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
