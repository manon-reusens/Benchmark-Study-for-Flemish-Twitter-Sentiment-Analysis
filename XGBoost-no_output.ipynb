{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b57e429",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c0b695",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer\n",
    "import json\n",
    "from collections import Counter\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn import metrics\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb2f903",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import numpy as np\n",
    "import copy\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn import metrics\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafc755c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annotations=  pd.read_csv('C:/Users/u0146965/OneDrive - KU Leuven/Sentiment analysis/full_cleaned_dataset.csv')\n",
    "df_annotations# to display the first 5 lines of loaded data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a25e32",
   "metadata": {},
   "source": [
    "# XGBoost met TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2384e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#doe TIDF op de data\n",
    "def TFIDF(data, max_feat, n_gram):\n",
    "    vect=TfidfVectorizer(max_features=max_feat, stop_words= stopwords.words('dutch'), token_pattern=r'\\b[^\\d\\W][^\\d\\W]+\\b', ngram_range=n_gram).fit(data)\n",
    "    X= vect.fit_transform(data)\n",
    "    X=pd.DataFrame(X.toarray(), columns= vect.get_feature_names())\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebcc5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#zet de y-waarden goed\n",
    "def y_set(dataset_column):\n",
    "    y= dataset_column\n",
    "    y = y.replace('NEUTRAL','1')\n",
    "    y = y.replace('POSITIVE','2')\n",
    "    y = y.replace('NEGATIVE','0')\n",
    "    for i in y:\n",
    "        i=int(i)\n",
    "    new=[]\n",
    "    for i in y:\n",
    "        new.append(int(i))\n",
    "    \n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97705e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#definieer de confusion matrix\n",
    "def cf_mat(y_test, y_pred):\n",
    "    mat=confusion_matrix(y_test, y_pred)/len(y_test)\n",
    "    return sns.heatmap(mat, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75249b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def XgBoost(X, y_inputkolom, max_feat, n_gram, max_depth=3, learning_rate=0.1, n_est=100):\n",
    "    y= y_set(y_inputkolom)\n",
    "    \n",
    "    # Split the data into training and testing\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "    #do TFIDF\n",
    "    vect=TfidfVectorizer(max_features=max_feat, stop_words= stopwords.words('dutch'), token_pattern=r'\\b[^\\d\\W][^\\d\\W]+\\b', ngram_range=n_gram).fit(X_train)\n",
    "    X_train= vect.transform(X_train)\n",
    "    X_test= vect.transform(X_test)\n",
    "    X_train=pd.DataFrame(X_train.toarray(), columns= vect.get_feature_names())\n",
    "    X_test=pd.DataFrame(X_test.toarray(), columns= vect.get_feature_names())\n",
    "    \n",
    "    # Build XGBoost\n",
    "    model = XGBClassifier(use_label_encoder=False, max_depth= max_depth, learning_rate= learning_rate, n_estimators= n_est)\n",
    "    xg_boost=model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict the labels \n",
    "    y_predict = xg_boost.predict(X_test)\n",
    "    new=[]\n",
    "    for i in y_test:\n",
    "        new.append(int(i))\n",
    "        \n",
    "    y_pred=[]\n",
    "    for i in y_predict:\n",
    "        y_pred.append(int(i))\n",
    "    print(' The Macro F1 measure is', metrics.f1_score(new, y_pred, average='macro'))\n",
    "    print(' The Macro precision is',metrics.precision_score(new, y_pred, average='macro'))\n",
    "    print(' The Macro recall is',metrics.recall_score(new, y_pred, average='macro'))\n",
    "        \n",
    "    print('The Accuracy of the model is', accuracy_score(y_test, y_predict))\n",
    "    print('The confusion matrix looks as follows', cf_mat(y_test, y_predict))\n",
    "    #return y_predict, y_test, log_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75ad4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def XgBoost_val_tuning(X,y_inputkolom, max_feat, n_gram, max_depth=3, learning_rate=0.1, n_est=100):\n",
    "    y= y_set(y_inputkolom)\n",
    "    # Split the data into training and testing\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)\n",
    "    \n",
    "    vect=TfidfVectorizer(max_features=max_feat, stop_words= stopwords.words('dutch'), token_pattern=r'\\b[^\\d\\W][^\\d\\W]+\\b', ngram_range=n_gram).fit(X_train)\n",
    "    X_train= vect.transform(X_train)\n",
    "    X_val= vect.transform(X_val)\n",
    "    X_train=pd.DataFrame(X_train.toarray(), columns= vect.get_feature_names())\n",
    "    X_val=pd.DataFrame(X_val.toarray(), columns= vect.get_feature_names())\n",
    "\n",
    "    # Build a logistic regression\n",
    "    model = XGBClassifier(use_label_encoder=False, max_depth= max_depth, learning_rate= learning_rate, n_estimators= n_est)\n",
    "    xg_boost= model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict the labels \n",
    "    y_predict = xg_boost.predict(X_val)\n",
    "    acc_score= accuracy_score(y_val, y_predict)\n",
    "    print('The Accuracy of the model is', acc_score)\n",
    "    #print('The confusion matrix looks as follows', cf_mat(y_val, y_predict))\n",
    "    return acc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df0c837",
   "metadata": {},
   "source": [
    "# TFIDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9db58ec",
   "metadata": {},
   "source": [
    "## Textified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840b1fb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotje=[]\n",
    "max_feat_list=[1000, 2000, 3000, 4000,5000 , 6000, 8000, 10000, 12000]\n",
    "for i in max_feat_list:\n",
    "    print('the number of max_features is', i)\n",
    "    acc_score=XgBoost_val_tuning(df_annotations['text'],df_annotations['label'], i, (1,1))\n",
    "    plotje.append(acc_score)\n",
    "    print(acc_score)\n",
    "print(plotje)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3826258f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.xlabel('max_features')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(max_feat_list, plotje)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68388210",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in [(1,1),(1,2)]:\n",
    "    acc_score=XgBoost_val_tuning(df_annotations['text'],df_annotations['label'],4000, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cd9429",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotje=[]\n",
    "max_depth= [1, 2, 3, 4, 5,6,7,8,9,10]\n",
    "for i in max_depth:\n",
    "    acc_score=XgBoost_val_tuning(df_annotations['text'],df_annotations['label'],4000, (1,1) ,i)\n",
    "    plotje.append(acc_score)\n",
    "print(plotje)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cff69af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.xlabel('max_features')\n",
    "plt.ylabel('max_depth')\n",
    "plt.plot(max_depth, plotje)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1d9990",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotje=[]\n",
    "learning_r= [0.01, 0.05, 0.1, 0.2, 0.5, 0.8, 1,1.2, 1.5]\n",
    "for i in learning_r:\n",
    "    acc_score=XgBoost_val_tuning(df_annotations['text'],df_annotations['label'],4000, (1,1),10 ,i)\n",
    "    plotje.append(acc_score)\n",
    "print(plotje)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf88d4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.xlabel('max_features')\n",
    "plt.ylabel('learning_rate')\n",
    "plt.plot(learning_r, plotje)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e7cd6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotje=[]\n",
    "n_est= [10, 50, 80, 100, 120, 150]\n",
    "for i in n_est:\n",
    "    acc_score=XgBoost_val_tuning(df_annotations['text'],df_annotations['label'],4000, (1,1),10, 0.8,i)\n",
    "    plotje.append(acc_score)\n",
    "print(plotje)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dd27a7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.xlabel('n_est')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(n_est, plotje)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88f64a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "XgBoost(df_annotations['text'],df_annotations['label'],4000, (1,1),10, 0.8,150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e20c73",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640c8498",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotje=[]\n",
    "max_feat_list=[1000, 2000, 3000, 4000,5000 , 6000, 8000, 10000, 12000]\n",
    "for i in max_feat_list:\n",
    "    print('the number of max_features is', i)\n",
    "    acc_score=XgBoost_val_tuning(df_annotations['processed_annotations_joined'].astype('U'),df_annotations['label'], i, (1,1))\n",
    "    plotje.append(acc_score)\n",
    "    print(acc_score)\n",
    "print(plotje)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a4d7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.xlabel('max_features')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(max_feat_list, plotje)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fb8d1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in [(1,1),(1,2)]:\n",
    "    acc_score=XgBoost_val_tuning(df_annotations['processed_annotations_joined'].astype('U'),df_annotations['label'], 3000, i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9e1b06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotje=[]\n",
    "max_depth= [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "for i in max_depth:\n",
    "    acc_score=XgBoost_val_tuning(df_annotations['processed_annotations_joined'].astype('U'),df_annotations['label'], 3000, (1,1),i)\n",
    "    plotje.append(acc_score)\n",
    "print(plotje)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b404eeef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(max_depth, plotje)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d711fcf4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotje=[]\n",
    "learning_r= [0.01, 0.05, 0.1, 0.2, 0.5, 0.8, 1,1.2, 1.5]\n",
    "for i in learning_r:\n",
    "    acc_score=XgBoost_val_tuning(df_annotations['processed_annotations_joined'].astype('U'),df_annotations['label'], 3000, (1,1),10,i)\n",
    "    plotje.append(acc_score)\n",
    "print(plotje)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb81668",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.xlabel('learning_rate')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(learning_r, plotje)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82518f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotje=[]\n",
    "n_est= [10, 50, 80, 100, 120, 150]\n",
    "for i in n_est:\n",
    "    acc_score=XgBoost_val_tuning(df_annotations['processed_annotations_joined'].astype('U'),df_annotations['label'], 3000, (1,1),10,0.5, i)\n",
    "    plotje.append(acc_score)\n",
    "print(plotje)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d649ebaa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.xlabel('n_est')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(n_est, plotje)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0662cd6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "XgBoost(df_annotations['processed_annotations_joined'].astype('U'),df_annotations['label'], 3000, (1,1),10,0.5, 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ca90c3",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382755ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotje=[]\n",
    "max_feat_list=[1000, 2000, 3000, 4000,5000 , 6000, 8000, 10000, 12000]\n",
    "for i in max_feat_list:\n",
    "    print('the number of max_features is', i)\n",
    "    acc_score=XgBoost_val_tuning(df_annotations['processed_annotations_lemmatized_joined'].astype('U'),df_annotations['label'], i, (1,1))\n",
    "    plotje.append(acc_score)\n",
    "    print(acc_score)\n",
    "print(plotje)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32957c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.xlabel('max_features')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(max_feat_list, plotje)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc806d7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in [(1,1),(1,2)]:\n",
    "    acc_score=XgBoost_val_tuning(df_annotations['processed_annotations_lemmatized_joined'].astype('U'),df_annotations['label'], 5000, i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e1b512",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plotje=[]\n",
    "max_depth= [1, 2, 3, 4, 5,6,7,8,9,10]\n",
    "for i in max_depth:\n",
    "    acc_score=XgBoost_val_tuning(df_annotations['processed_annotations_lemmatized_joined'].astype('U'),df_annotations['label'], 5000, (1,1),i)\n",
    "    plotje.append(acc_score)\n",
    "print(plotje)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06aa5b1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(max_depth, plotje)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021bc5e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotje=[]\n",
    "learning_r= [0.01, 0.05, 0.1, 0.2, 0.5, 0.8, 1,1.2, 1.5]\n",
    "for i in learning_r:\n",
    "    acc_score=XgBoost_val_tuning(df_annotations['processed_annotations_lemmatized_joined'].astype('U'),df_annotations['label'], 5000, (1,1),10,i)\n",
    "    plotje.append(acc_score)\n",
    "print(plotje)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b99cde2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.xlabel('learning_rate')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(learning_r, plotje)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9458e599",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotje=[]\n",
    "n_est= [10, 50, 80, 100, 120, 150]\n",
    "for i in n_est:\n",
    "    acc_score=XgBoost_val_tuning(df_annotations['processed_annotations_lemmatized_joined'].astype('U'),df_annotations['label'], 5000, (1,1),10,0.5,i)\n",
    "    plotje.append(acc_score)\n",
    "print(plotje)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4b8edc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.xlabel('n_est')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(n_est, plotje)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b10a50d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "XgBoost(df_annotations['processed_annotations_lemmatized_joined'].astype('U'),df_annotations['label'], 5000, (1,1),10,0.5,150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef666be8",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2a9d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent(data_column):\n",
    "    sentences=[]\n",
    "    for i in data_column:\n",
    "        if type(i)!=float:\n",
    "            words_in_sentence=i.split()\n",
    "            sentences.append(words_in_sentence)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcead44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def XgBoost(X, y_inputkolom, vector_s, wind=5, min_c=1, work=4, sg=1, alpha= 0.025, max_depth=3, learning_rate=0.1, n_est=100):\n",
    "    y= y_set(y_inputkolom)\n",
    "    \n",
    "    # Split the data into training and testing\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "    model= Word2Vec(sentences=sent(X_train), vector_size=vector_s, window=wind, min_count=min_c, workers=work, sg=sg, alpha=alpha)\n",
    "    Word2Vec_text_av=[]\n",
    "    for i in X_train:\n",
    "        l=[]\n",
    "        for word in i.split():\n",
    "            if word in model.wv.key_to_index:\n",
    "                l.append(list(model.wv.get_vector(word)))\n",
    "            else:\n",
    "                l.append([0]*vector_s)\n",
    "        avg = [float(sum(col))/len(col) for col in zip(*l)]\n",
    "        Word2Vec_text_av.append(avg)\n",
    "    X_train=pd.DataFrame(Word2Vec_text_av)\n",
    "    \n",
    "    Word2Vec_text_av=[]\n",
    "    for i in X_test:\n",
    "        l=[]\n",
    "        for word in i.split():\n",
    "            if word in model.wv.key_to_index:\n",
    "                l.append(list(model.wv.get_vector(word)))\n",
    "            else:\n",
    "                l.append([0]*vector_s)\n",
    "        avg = [float(sum(col))/len(col) for col in zip(*l)]\n",
    "        Word2Vec_text_av.append(avg)\n",
    "    X_test=pd.DataFrame(Word2Vec_text_av)\n",
    "    \n",
    "    # Build XGBoost\n",
    "    model = XGBClassifier(use_label_encoder=False, max_depth= max_depth, learning_rate= learning_rate, n_estimators= n_est)\n",
    "    xg_boost=model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict the labels \n",
    "    y_predict = xg_boost.predict(X_test)\n",
    "    new=[]\n",
    "    for i in y_test:\n",
    "        new.append(int(i))\n",
    "        \n",
    "    y_pred=[]\n",
    "    for i in y_predict:\n",
    "        y_pred.append(int(i))\n",
    "    print(' The Macro F1 measure is', metrics.f1_score(new, y_pred, average='macro'))\n",
    "    print(' The Macro precision is',metrics.precision_score(new, y_pred, average='macro'))\n",
    "    print(' The Macro recall is',metrics.recall_score(new, y_pred, average='macro'))\n",
    "        \n",
    "    print('The Accuracy of the model is', accuracy_score(y_test, y_predict))\n",
    "    print('The confusion matrix looks as follows', cf_mat(y_test, y_predict))\n",
    "    #return y_predict, y_test, log_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd75c984",
   "metadata": {},
   "outputs": [],
   "source": [
    "def XgBoost_val_tuning(X,y_inputkolom, vector_s, wind=5, min_c=1, work=4, sg=1, alpha= 0.025, max_depth=3, learning_rate=0.1, n_est=100):\n",
    "    y= y_set(y_inputkolom)\n",
    "    # Split the data into training and testing\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)\n",
    "    \n",
    "    model= Word2Vec(sentences=sent(X_train), vector_size=vector_s, window=wind, min_count=min_c, workers=work, sg=sg, alpha=alpha)\n",
    "    Word2Vec_text_av=[]\n",
    "    for i in X_train:\n",
    "        l=[]\n",
    "        for word in i.split():\n",
    "            if word in model.wv.key_to_index:\n",
    "                l.append(list(model.wv.get_vector(word)))\n",
    "            else:\n",
    "                l.append([0]*vector_s)\n",
    "        avg = [float(sum(col))/len(col) for col in zip(*l)]\n",
    "        #a = np.array(l)\n",
    "        #print(a)\n",
    "        #res = np.average(a, axis=0)\n",
    "        #lijst=list(res)\n",
    "        Word2Vec_text_av.append(avg)\n",
    "    X_train=pd.DataFrame(Word2Vec_text_av)\n",
    "    \n",
    "    Word2Vec_text_av=[]\n",
    "    for i in X_val:\n",
    "        l=[]\n",
    "        for word in i.split():\n",
    "            if word in model.wv.key_to_index:\n",
    "                l.append(list(model.wv.get_vector(word)))\n",
    "            else:\n",
    "                l.append([0]*vector_s)\n",
    "        avg = [float(sum(col))/len(col) for col in zip(*l)]\n",
    "        #a = np.array(l)\n",
    "        #print(a)\n",
    "        #res = np.average(a, axis=0)\n",
    "        #lijst=list(res)\n",
    "        Word2Vec_text_av.append(avg)\n",
    "    X_val=pd.DataFrame(Word2Vec_text_av)\n",
    "\n",
    "    # Build a logistic regression\n",
    "    model = XGBClassifier(use_label_encoder=False, max_depth= max_depth, learning_rate= learning_rate, n_estimators= n_est)\n",
    "    xg_boost= model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict the labels \n",
    "    y_predict = xg_boost.predict(X_val)\n",
    "    acc_score= accuracy_score(y_val, y_predict)\n",
    "    print('The Accuracy of the model is', acc_score)\n",
    "    #print('The confusion matrix looks as follows', cf_mat(y_val, y_predict))\n",
    "    return acc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b05c5ce",
   "metadata": {},
   "source": [
    "## Textified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dd674c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotje=[]\n",
    "max_vect= [50,100,200,300,500,600,700,1000]\n",
    "for i in max_vect:\n",
    "    acc_score=XgBoost_val_tuning(df_annotations['text'],df_annotations['label'], i)\n",
    "    plotje.append(acc_score)\n",
    "    print(acc_score)\n",
    "print(plotje)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42289604",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.xlabel('max_features')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(max_vect, plotje)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a40bcaf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotje=[]\n",
    "wind= [1,2,3,4,5,6,7,8,9,10, 12, 15, 20]\n",
    "for i in wind:\n",
    "    acc_score=XgBoost_val_tuning(df_annotations['text'],df_annotations['label'],1000, i)\n",
    "    plotje.append(acc_score)\n",
    "    print(acc_score)\n",
    "print(plotje)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce3e226",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotje=[]\n",
    "wind= [12, 15, 20]\n",
    "for i in wind:\n",
    "    acc_score=XgBoost_val_tuning(df_annotations['text'],df_annotations['label'],1000, i)\n",
    "    plotje.append(acc_score)\n",
    "    print(acc_score)\n",
    "print(plotje)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07c42ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.xlabel('window')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(wind, plotje)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d224d0fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotje=[]\n",
    "min_c= [0,1,2,3,4,5,6,7,8,9,10,20]\n",
    "for i in min_c:\n",
    "    acc_score=XgBoost_val_tuning(df_annotations['text'],df_annotations['label'],1000,10, i)\n",
    "    plotje.append(acc_score)\n",
    "    print(acc_score)\n",
    "print(plotje)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040c5517",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.xlabel('min_count')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(min_c, plotje)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979961c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotje=[]\n",
    "for i in [0,1]:\n",
    "    acc_score=XgBoost_val_tuning(df_annotations['text'],df_annotations['label'],1000,10,4,16 ,i)\n",
    "    plotje.append(acc_score)\n",
    "    print(acc_score)\n",
    "print(plotje)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80c4bff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotje=[]\n",
    "alphas= [0.01,0.025,0.05,0.1,0.15,0.2,0.3,0.4,0.5,0.8,1]\n",
    "for i in alphas:\n",
    "    acc_score=XgBoost_val_tuning(df_annotations['text'],df_annotations['label'],1000,10,4,16, 1,i)\n",
    "    plotje.append(acc_score)\n",
    "    print(acc_score)\n",
    "print(plotje)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080d8cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(plotje)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa22254",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotje=[]\n",
    "max_depth= [1, 2, 3, 4, 5,6,7,8,9,10]\n",
    "for i in max_depth:\n",
    "    acc_score=XgBoost_val_tuning(df_annotations['text'],df_annotations['label'],1000,10,4,16, 1,0.15,i)\n",
    "    plotje.append(acc_score)\n",
    "print(plotje)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b7b3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(plotje)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4616ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(max_depth, plotje)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d6bd99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotje=[]\n",
    "learning_r= [0.01, 0.05, 0.1, 0.2, 0.5, 0.8, 1,1.2, 1.5]\n",
    "for i in learning_r:\n",
    "    acc_score=XgBoost_val_tuning(df_annotations['text'],df_annotations['label'],1000,10,4,16, 1,0.15,8,i)\n",
    "    plotje.append(acc_score)\n",
    "print(plotje)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b086cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(learning_r, plotje)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f02719e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotje=[]\n",
    "n_est= [10, 50, 80, 100, 120, 150]\n",
    "for i in n_est:\n",
    "    acc_score=XgBoost_val_tuning(df_annotations['text'],df_annotations['label'],1000,10,4,16, 1,0.15,8,0.1,i)\n",
    "    plotje.append(acc_score)\n",
    "print(plotje)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacf5401",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.xlabel('n_est')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(n_est, plotje)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef20c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "XgBoost(df_annotations['text'],df_annotations['label'],1000,10,4,16, 1,0.15,8,0.1,150)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba90c41",
   "metadata": {},
   "source": [
    "## lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285e81b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def XgBoost_val_tuning_lem(X,y_inputkolom, vector_s, wind=5, min_c=1, work=4, sg=1, alpha= 0.025, max_depth=3, learning_rate=0.1, n_est=100):\n",
    "    y= y_set(y_inputkolom)\n",
    "    # Split the data into training and testing\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)\n",
    "    \n",
    "    model= Word2Vec(sentences=sent(X_train), vector_size=vector_s, window=wind, min_count=min_c, workers=work, sg=sg, alpha=alpha)\n",
    "    Word2Vec_text_av=[]\n",
    "    for i in X_train:\n",
    "        l=[]\n",
    "        if type(i)== float:\n",
    "            l.append([0]*vector_s)\n",
    "        else:\n",
    "            for word in i.split():\n",
    "                if word in model.wv.key_to_index:\n",
    "                    l.append(list(model.wv.get_vector(word)))\n",
    "                else:\n",
    "                    l.append([0]*vector_s)\n",
    "        avg = [float(sum(col))/len(col) for col in zip(*l)]\n",
    "        #a = np.array(l)\n",
    "        #print(a)\n",
    "        #res = np.average(a, axis=0)\n",
    "        #lijst=list(res)\n",
    "        Word2Vec_text_av.append(avg)\n",
    "    X_train=pd.DataFrame(Word2Vec_text_av)\n",
    "    \n",
    "    Word2Vec_text_av=[]\n",
    "    for i in X_val:\n",
    "        l=[]\n",
    "        if type(i)== float:\n",
    "            l.append([0]*vector_s)\n",
    "        else:\n",
    "            for word in i.split():\n",
    "                if word in model.wv.key_to_index:\n",
    "                    l.append(list(model.wv.get_vector(word)))\n",
    "                else:\n",
    "                    l.append([0]*vector_s)\n",
    "        avg = [float(sum(col))/len(col) for col in zip(*l)]\n",
    "        #a = np.array(l)\n",
    "        #print(a)\n",
    "        #res = np.average(a, axis=0)\n",
    "        #lijst=list(res)\n",
    "        Word2Vec_text_av.append(avg)\n",
    "    X_val=pd.DataFrame(Word2Vec_text_av)\n",
    "\n",
    "    # Build an XGBoost\n",
    "    model = XGBClassifier(use_label_encoder=False, max_depth= max_depth, learning_rate= learning_rate, n_estimators= n_est)\n",
    "    xg_boost= model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict the labels \n",
    "    y_predict = xg_boost.predict(X_val)\n",
    "    acc_score= accuracy_score(y_val, y_predict)\n",
    "    print('The Accuracy of the model is', acc_score)\n",
    "    #print('The confusion matrix looks as follows', cf_mat(y_val, y_predict))\n",
    "    return acc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a513c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def XgBoost_lem(X, y_inputkolom, vector_s, wind=5, min_c=1, work=4, sg=1, alpha= 0.025, max_depth=3, learning_rate=0.1, n_est=100):\n",
    "    y= y_set(y_inputkolom)\n",
    "    \n",
    "    # Split the data into training and testing\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "    model= Word2Vec(sentences=sent(X_train), vector_size=vector_s, window=wind, min_count=min_c, workers=work, sg=sg, alpha=alpha)\n",
    "    Word2Vec_text_av=[]\n",
    "    for i in X_train:\n",
    "        l=[]\n",
    "        if type(i)== float:\n",
    "            l.append([0]*vector_s)\n",
    "        else:\n",
    "            for word in i.split():\n",
    "                if word in model.wv.key_to_index:\n",
    "                    l.append(list(model.wv.get_vector(word)))\n",
    "                else:\n",
    "                    l.append([0]*vector_s)\n",
    "        avg = [float(sum(col))/len(col) for col in zip(*l)]\n",
    "        Word2Vec_text_av.append(avg)\n",
    "    X_train=pd.DataFrame(Word2Vec_text_av)\n",
    "    \n",
    "    Word2Vec_text_av=[]\n",
    "    for i in X_test:\n",
    "        l=[]\n",
    "        if type(i)== float:\n",
    "            l.append([0]*vector_s)\n",
    "        else:\n",
    "            for word in i.split():\n",
    "                if word in model.wv.key_to_index:\n",
    "                    l.append(list(model.wv.get_vector(word)))\n",
    "                else:\n",
    "                    l.append([0]*vector_s)\n",
    "        avg = [float(sum(col))/len(col) for col in zip(*l)]\n",
    "        Word2Vec_text_av.append(avg)\n",
    "    X_test=pd.DataFrame(Word2Vec_text_av)\n",
    "    \n",
    "    # Build XGBoost\n",
    "    model = XGBClassifier(use_label_encoder=False, max_depth= max_depth, learning_rate= learning_rate, n_estimators= n_est)\n",
    "    xg_boost=model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict the labels \n",
    "    y_predict = xg_boost.predict(X_test)\n",
    "    new=[]\n",
    "    for i in y_test:\n",
    "        new.append(int(i))\n",
    "        \n",
    "    y_pred=[]\n",
    "    for i in y_predict:\n",
    "        y_pred.append(int(i))\n",
    "    print(' The Macro F1 measure is', metrics.f1_score(new, y_pred, average='macro'))\n",
    "    print(' The Macro precision is',metrics.precision_score(new, y_pred, average='macro'))\n",
    "    print(' The Macro recall is',metrics.recall_score(new, y_pred, average='macro'))\n",
    "        \n",
    "    print('The Accuracy of the model is', accuracy_score(y_test, y_predict))\n",
    "    print('The confusion matrix looks as follows', cf_mat(y_test, y_predict))\n",
    "    #return y_predict, y_test, log_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7811ae3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotje=[]\n",
    "max_vect= [50,100,200,300,500,600,700,1000]\n",
    "for i in max_vect:\n",
    "    acc_score=XgBoost_val_tuning_lem(df_annotations['processed_annotations_lemmatized_joined'].astype('U'),df_annotations['label'], i)\n",
    "    plotje.append(acc_score)\n",
    "    print(acc_score)\n",
    "print(plotje)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8742026e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.xlabel('max_features')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(max_vect, plotje)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74d9439",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotje=[]\n",
    "wind= [1,2,3,4,5,6,7,8,9,10, 12, 15, 20]\n",
    "for i in wind:\n",
    "    acc_score=XgBoost_val_tuning_lem(df_annotations['processed_annotations_lemmatized_joined'].astype('U'),df_annotations['label'], 300,i)\n",
    "    plotje.append(acc_score)\n",
    "    print(acc_score)\n",
    "print(plotje)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7fe89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.xlabel('window')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(wind, plotje)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083ee814",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotje=[]\n",
    "min_c= [0,1,2,3,4,5,6,7,8,9,10,20]\n",
    "for i in min_c:\n",
    "    acc_score=XgBoost_val_tuning_lem(df_annotations['processed_annotations_lemmatized_joined'].astype('U'),df_annotations['label'], 300,15, i)\n",
    "    plotje.append(acc_score)\n",
    "    print(acc_score)\n",
    "print(plotje)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485108b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.xlabel('min_count')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(min_c, plotje)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22afe50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotje=[]\n",
    "for i in [0,1]:\n",
    "    acc_score=XgBoost_val_tuning_lem(df_annotations['processed_annotations_lemmatized_joined'].astype('U'),df_annotations['label'], 300,15,6,16, i)\n",
    "    plotje.append(acc_score)\n",
    "    print(acc_score)\n",
    "print(plotje)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b64884",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotje=[]\n",
    "alphas= [0.01,0.025,0.05,0.1,0.15,0.2,0.3,0.4,0.5,0.8,1]\n",
    "for i in alphas:\n",
    "    acc_score=XgBoost_val_tuning_lem(df_annotations['processed_annotations_lemmatized_joined'].astype('U'),df_annotations['label'], 300,15,6,16,1, i)\n",
    "    plotje.append(acc_score)\n",
    "    print(acc_score)\n",
    "print(plotje)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d24ef48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.xlabel('Alpha')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(alphas, plotje)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4124af55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotje=[]\n",
    "max_depth= [1, 2, 3, 4, 5,6,7,8,9,10]\n",
    "for i in max_depth:\n",
    "    acc_score=XgBoost_val_tuning_lem(df_annotations['processed_annotations_lemmatized_joined'].astype('U'),df_annotations['label'], 300,15,6,16,1,0.1, i)\n",
    "    plotje.append(acc_score)\n",
    "print(plotje)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926ecf4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(max_depth, plotje)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c159e89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotje=[]\n",
    "learning_r= [0.01, 0.05, 0.1, 0.2, 0.5, 0.8, 1,1.2, 1.5]\n",
    "for i in learning_r:\n",
    "    acc_score=XgBoost_val_tuning_lem(df_annotations['processed_annotations_lemmatized_joined'].astype('U'),df_annotations['label'], 300,15,6,16,1, 0.1,9,i)\n",
    "    plotje.append(acc_score)\n",
    "print(plotje)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073e85f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.xlabel('learning_rate')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(learning_r, plotje)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc35cb5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotje=[]\n",
    "n_est= [10, 50, 80, 100, 120, 150]\n",
    "for i in n_est:\n",
    "    acc_score=XgBoost_val_tuning_lem(df_annotations['processed_annotations_lemmatized_joined'].astype('U'),df_annotations['label'], 300,15,6,16,1, 0.1,9,0.2,i)\n",
    "    plotje.append(acc_score)\n",
    "print(plotje)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ebb739",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(n_est, plotje)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e61b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_score=XgBoost(df_annotations['processed_annotations_lemmatized_joined'].astype('U'),df_annotations['label'], 300,15,6,16,1, 0.1,9,0.2,150)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00aaea2d",
   "metadata": {},
   "source": [
    "# Word2Vec pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b0e31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def XgBoost(X, y_inputkolom, max_depth=3, learning_rate=0.1, n_est=100):\n",
    "    y= y_set(y_inputkolom)\n",
    "    \n",
    "    # Split the data into training and testing\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "    # Build a logistic regression\n",
    "    model = XGBClassifier(use_label_encoder=False, max_depth= max_depth, learning_rate= learning_rate, n_estimators= n_est)\n",
    "    xg_boost=model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict the labels \n",
    "    y_predict = xg_boost.predict(X_test)\n",
    "    new=[]\n",
    "    for i in y_test:\n",
    "        new.append(int(i))\n",
    "        \n",
    "    y_pred=[]\n",
    "    for i in y_predict:\n",
    "        y_pred.append(int(i))\n",
    "    print(' The Macro F1 measure is', metrics.f1_score(new, y_pred, average='macro'))\n",
    "    print(' The Macro precision is',metrics.precision_score(new, y_pred, average='macro'))\n",
    "    print(' The Macro recall is',metrics.recall_score(new, y_pred, average='macro'))\n",
    "        \n",
    "    print('The Accuracy of the model is', accuracy_score(y_test, y_predict))\n",
    "    print('The confusion matrix looks as follows', cf_mat(y_test, y_predict))\n",
    "    #return y_predict, y_test, log_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e204bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def XgBoost_val_tuning(X,y_inputkolom, max_depth=3, learning_rate=0.1, n_est=100):\n",
    "    y= y_set(y_inputkolom)\n",
    "    # Split the data into training and testing\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)\n",
    "    \n",
    "\n",
    "    # Build a logistic regression\n",
    "    model = XGBClassifier(use_label_encoder=False, max_depth= max_depth, learning_rate= learning_rate, n_estimators= n_est)\n",
    "    xg_boost= model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict the labels \n",
    "    y_predict = xg_boost.predict(X_val)\n",
    "    acc_score= accuracy_score(y_val, y_predict)\n",
    "    print('The Accuracy of the model is', acc_score)\n",
    "    #print('The confusion matrix looks as follows', cf_mat(y_val, y_predict))\n",
    "    return acc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304d13e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('model.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fe1ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def W2V_pretrained_emb(data):\n",
    "    Word2Vec_text_av=[]\n",
    "    for i in range(len(data)):\n",
    "        l=[]\n",
    "        \n",
    "        if type(data[i])== float:\n",
    "            l.append([0]*300)\n",
    "        else:\n",
    "            for word in data[i].split():\n",
    "                if word in model.key_to_index:\n",
    "                    l.append(list(model.get_vector(word)))\n",
    "                else:\n",
    "                    l.append([0]*300)\n",
    "        avg = [float(sum(col))/len(col) for col in zip(*l)]\n",
    "        Word2Vec_text_av.append(avg)\n",
    "    X=pd.DataFrame(Word2Vec_text_av)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcc6cd8",
   "metadata": {},
   "source": [
    "## Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d099e4d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotje=[]\n",
    "max_depth= [1, 2, 3, 4, 5,6,7,8,9,10]\n",
    "X=W2V_pretrained_emb(df_annotations['text'])\n",
    "for i in max_depth:\n",
    "    acc_score=XgBoost_val_tuning(X, df_annotations['label'], max_depth=i)\n",
    "    plotje.append(acc_score)\n",
    "print(plotje)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6c3a8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(max_depth, plotje)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d61055",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotje=[]\n",
    "learning_r= [0.01, 0.05, 0.1, 0.2, 0.5, 0.8, 1,1.2, 1.5]\n",
    "X=W2V_pretrained_emb(df_annotations['text'])\n",
    "for i in learning_r:\n",
    "    acc_score=XgBoost_val_tuning(X, df_annotations['label'], 9,learning_rate=i)\n",
    "    plotje.append(acc_score)\n",
    "print(plotje)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c7b131",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "objects=learning_r\n",
    "y_pos= np.arange(len(objects))\n",
    "plt.bar(y_pos, plotje, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('learning_rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee2a140",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotje=[]\n",
    "n_est= [10, 50, 80, 100, 120, 150]\n",
    "X=W2V_pretrained_emb(df_annotations['text'])\n",
    "for i in n_est:\n",
    "    acc_score=XgBoost_val_tuning(X, df_annotations['label'], 9,learning_rate=0.1, n_est= i)\n",
    "    plotje.append(acc_score)\n",
    "print(plotje)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223b51ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(n_est, plotje)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f9bee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=W2V_pretrained_emb(df_annotations['text'])\n",
    "acc_score=XgBoost(X, df_annotations['label'], 9, learning_rate=0.1, n_est= 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f760289",
   "metadata": {},
   "source": [
    "## Lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0790ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotje=[]\n",
    "max_depth= [1, 2, 3, 4, 5,6,7,8,9,10]\n",
    "X=W2V_pretrained_emb(df_annotations['processed_annotations_lemmatized_joined'])\n",
    "for i in max_depth:\n",
    "    acc_score=XgBoost_val_tuning(X, df_annotations['label'], max_depth=i)\n",
    "    plotje.append(acc_score)\n",
    "print(plotje)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b42a01e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(max_depth, plotje)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0951b222",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotje=[]\n",
    "learning_r= [0.01, 0.05, 0.1, 0.2, 0.5, 0.8, 1,1.2, 1.5]\n",
    "X=W2V_pretrained_emb(df_annotations['processed_annotations_lemmatized_joined'])\n",
    "for i in learning_r:\n",
    "    acc_score=XgBoost_val_tuning(X, df_annotations['label'],10, learning_rate=i)\n",
    "    plotje.append(acc_score)\n",
    "print(plotje)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a6fd21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "objects=learning_r\n",
    "y_pos= np.arange(len(objects))\n",
    "plt.bar(y_pos, plotje, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('learning_rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e3dcad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotje=[]\n",
    "n_est= [10, 50, 80, 100, 120, 150,200,250,300,350,400]\n",
    "X= W2V_pretrained_emb(df_annotations['processed_annotations_lemmatized_joined'])\n",
    "for i in n_est:\n",
    "    acc_score=XgBoost_val_tuning(X, df_annotations['label'], 10,0.1, n_est= i)\n",
    "    plotje.append(acc_score)\n",
    "print(plotje)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433482d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.xlabel('n_est')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(n_est, plotje)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7cfd62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotje=[]\n",
    "n_est= [350,400,450,500,550,600]\n",
    "X= W2V_pretrained_emb(df_annotations['processed_annotations_lemmatized_joined'])\n",
    "for i in n_est:\n",
    "    acc_score=XgBoost_val_tuning(X, df_annotations['label'],10,0.1, n_est= i)\n",
    "    plotje.append(acc_score)\n",
    "print(plotje)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c9e890",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.xlabel('n_est')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(n_est, plotje)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ae0e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=W2V_pretrained_emb(df_annotations['processed_annotations_lemmatized_joined'])\n",
    "acc_score=XgBoost(X, df_annotations['label'],10,0.1, 120)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601cd4d6",
   "metadata": {},
   "source": [
    "# fasttext pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a751066b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import fasttext.util\n",
    "model = fasttext.load_model('cc.nl.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05494e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fasttext_pretrained_emb(data):\n",
    "    fasttext_text_av=[]\n",
    "    for i in range(len(data)):\n",
    "        l=[]\n",
    "        \n",
    "        if type(data[i])== float:\n",
    "            l.append([0]*300)\n",
    "        else:\n",
    "            for word in data[i].split():\n",
    "                l.append(list(model.get_word_vector(word)))\n",
    "        avg = [float(sum(col))/len(col) for col in zip(*l)]\n",
    "        fasttext_text_av.append(avg)\n",
    "    X=pd.DataFrame(fasttext_text_av)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6054dbfe",
   "metadata": {},
   "source": [
    "## Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72680526",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotje=[]\n",
    "max_depth= [1, 2, 3, 4, 5,6,7,8,9,10]\n",
    "X=fasttext_pretrained_emb(df_annotations['text'])\n",
    "for i in max_depth:\n",
    "    acc_score=XgBoost_val_tuning(X, df_annotations['label'],max_depth=i)\n",
    "    plotje.append(acc_score)\n",
    "print(plotje)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1bdb2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(max_depth, plotje)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec66f33d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotje=[]\n",
    "learning_r= [0.01, 0.05, 0.1, 0.2, 0.5, 0.8, 1,1.2, 1.5]\n",
    "X=fasttext_pretrained_emb(df_annotations['text'])\n",
    "for i in learning_r:\n",
    "    acc_score=XgBoost_val_tuning(X, df_annotations['label'],9, learning_rate=i)\n",
    "    plotje.append(acc_score)\n",
    "print(plotje)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0c2f88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "objects=learning_r\n",
    "y_pos= np.arange(len(objects))\n",
    "plt.bar(y_pos, plotje, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('learning_rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80735480",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotje=[]\n",
    "n_est= [10, 50, 80, 100, 120, 150]\n",
    "X=fasttext_pretrained_emb(df_annotations['text'])\n",
    "for i in n_est:\n",
    "    acc_score=XgBoost_val_tuning(X, df_annotations['label'], 9, learning_rate=0.1, n_est= i)\n",
    "    plotje.append(acc_score)\n",
    "print(plotje)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f847975e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(n_est, plotje)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e395bce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=fasttext_pretrained_emb(df_annotations['text'])\n",
    "acc_score=XgBoost(X, df_annotations['label'],9, learning_rate=0.1, n_est= 120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc1cdca",
   "metadata": {},
   "source": [
    "## Lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee711be3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotje=[]\n",
    "max_depth= [1, 2, 3, 4, 5,6,7,8,9,10]\n",
    "X=fasttext_pretrained_emb(df_annotations['processed_annotations_lemmatized_joined'])\n",
    "for i in max_depth:\n",
    "    acc_score=XgBoost_val_tuning(X, df_annotations['label'],i)\n",
    "    plotje.append(acc_score)\n",
    "print(plotje)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624af80e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(max_depth, plotje)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af40c580",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotje=[]\n",
    "learning_r= [0.01, 0.05, 0.1, 0.2, 0.5, 0.8, 1,1.2, 1.5]\n",
    "X=fasttext_pretrained_emb(df_annotations['processed_annotations_lemmatized_joined'])\n",
    "for i in learning_r:\n",
    "    acc_score=XgBoost_val_tuning(X, df_annotations['label'], 8,learning_rate=i)\n",
    "    plotje.append(acc_score)\n",
    "print(plotje)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a9f824",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "objects=learning_r\n",
    "y_pos= np.arange(len(objects))\n",
    "plt.bar(y_pos, plotje, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('learning_rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d0c9c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotje=[]\n",
    "n_est= [10, 50, 80, 100, 120, 150]\n",
    "X= fasttext_pretrained_emb(df_annotations['processed_annotations_lemmatized_joined'])\n",
    "for i in n_est:\n",
    "    acc_score=XgBoost_val_tuning(X, df_annotations['label'],8, 0.1, n_est= i)\n",
    "    plotje.append(acc_score)\n",
    "print(plotje)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a3bac4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.xlabel('n_est')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(n_est, plotje)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78afcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=fasttext_pretrained_emb(df_annotations['processed_annotations_lemmatized_joined'])\n",
    "acc_score=XgBoost(X, df_annotations['label'],8,0.1,150)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
