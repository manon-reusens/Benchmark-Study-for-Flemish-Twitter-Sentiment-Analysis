{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Dropout, Activation, Bidirectional\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from keras.utils.np_utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.models import load_model\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import gensim\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import numpy as np\n",
    "import copy\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annotations=  pd.read_csv('full_cleaned_dataset.csv')\n",
    "data = df_annotations[['text','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab_size_val(data,label):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data,label , test_size=0.3, random_state=42, stratify=label)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train,y_train , test_size=0.2, random_state=42, stratify=y_train)\n",
    "    t = Tokenizer()\n",
    "    t.fit_on_texts(X_train)\n",
    "    vocab_size = len(t.word_index) + 1\n",
    "    return vocab_size\n",
    "def get_vocab_size(data,label):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data,label , test_size=0.3, random_state=42, stratify=label)\n",
    "    t = Tokenizer()\n",
    "    t.fit_on_texts(X_train)\n",
    "    vocab_size = len(t.word_index) + 1\n",
    "    return vocab_size\n",
    "\n",
    "def one_hot_enc(data, label, max_length):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data,label , test_size=0.3, random_state=42, stratify=label)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train,y_train , test_size=0.2, random_state=42, stratify=y_train)\n",
    "    #print(y_test)\n",
    "    t = Tokenizer()\n",
    "    t.fit_on_texts(X_train)\n",
    "    vocab_size = len(t.word_index) + 1\n",
    "    #print(vocab_size)\n",
    "    \n",
    "    train_seq_nopad = t.texts_to_sequences(X_train)\n",
    "    val_seq_nopad  = t.texts_to_sequences(X_val)\n",
    "    test_seq_nopad  = t.texts_to_sequences(X_test)\n",
    "\n",
    "    padded_train = pad_sequences(train_seq_nopad, maxlen=max_length, padding='post')\n",
    "    padded_val = pad_sequences(val_seq_nopad, maxlen=max_length, padding='post')\n",
    "    padded_test = pad_sequences(test_seq_nopad, maxlen=max_length, padding='post')\n",
    "    \n",
    "    return padded_train, padded_val,padded_test, vocab_size\n",
    "    \n",
    "def change_y(y):\n",
    "    values = np.array(y)\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(values)\n",
    "    #print(integer_encoded)\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "    return onehot_encoded\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "onehot_encoded=change_y(data['label'])\n",
    "vocab_size_val= get_vocab_size_val(data['text'],data['label'])\n",
    "vocab_size=get_vocab_size(data['text'],data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def bidir_LSTM_1_hidden_layer_lr( model_name, name_accplot, name_lossplot, name_acc_csv, name_loss_csv,  lr, y, data, emb_len, max_length, lstm_out, batch_size, epochs, kernel_reg= 1e-3, rec_reg=1e-3, bias_reg=1e-3, act_reg=1e-3, drop_out=0.2, rec_drop=0.2):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, onehot_encoded, test_size=0.3, random_state=42, stratify=y)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train) \n",
    "    X_train, X_val, X_test, vocab_size=one_hot_enc(data, y, 500)\n",
    "    #print(y_test)\n",
    "    #model\n",
    "    e = Embedding(vocab_size, emb_len, mask_zero=True, input_length=max_length)\n",
    "    model= Sequential()\n",
    "    model.add(e)\n",
    "    model.add(Bidirectional(LSTM(lstm_out, dropout=drop_out, recurrent_dropout= rec_drop, kernel_regularizer=l2(kernel_reg),\n",
    "            recurrent_regularizer= l2(rec_reg),bias_regularizer=l2(bias_reg), activity_regularizer=l2(act_reg))))#return_sequences=True\n",
    "    model.add(Dense(units=3, activation='softmax'))\n",
    "    optimizer= Adam(learning_rate=lr)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['acc'])\n",
    "    print(' the model looks like this for the following parameters: the vocabulary size is ', vocab_size, 'the embedded_length is ', emb_len, 'the maximum length is ',max_length, 'the number of hidden nodes is ', lstm_out, 'The batch size is ',  batch_size, 'the number of epochs is ', epochs, 'the dropout of the dropout layer is ', drop_out )\n",
    "\n",
    "    callback = LearningRateScheduler(scheduler, verbose=1)\n",
    "    es= EarlyStopping(monitor='val_acc', mode='max', verbose=1, patience=30)\n",
    "    mc = ModelCheckpoint(filepath=model_name, monitor='val_acc', mode='max', verbose=1, save_best_only=True, save_freq='epoch')\n",
    "    history=model.fit(X_train, y_train, batch_size=batch_size, callbacks=[callback, es, mc], epochs=epochs, validation_data=(X_val, y_val))\n",
    "    print(history.history.keys())\n",
    "    \n",
    "    # summarize history for accuracy\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    fig1 = plt.gcf()\n",
    "    fig1.savefig(name_accplot)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    df1=pd.DataFrame()\n",
    "    df1['acc']=history.history['acc']\n",
    "    df1['val_acc']=history.history['val_acc']\n",
    "    df1.to_csv(name_acc_csv)\n",
    "    \n",
    "    \n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    fig1 = plt.gcf()\n",
    "    fig1.savefig(name_lossplot)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    df2=pd.DataFrame()\n",
    "    df2['loss']=history.history['loss']\n",
    "    df2['val_loss']=history.history['val_loss']\n",
    "    df2.to_csv(name_loss_csv)\n",
    "\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import math\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    elif lr <=1e-5:\n",
    "        return lr\n",
    "    else:\n",
    "        return float(lr * np.exp(-0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr=[1e-5,1e-6,1e-7]\n",
    "for i in lr:\n",
    "    bidir_LSTM_1_hidden_layer_lr('nodes_32_model.hdf5','nodes_32_acc.png', 'nodes_32_loss.png', 'nodes_32_acc.csv', 'nodes_32_loss.csv',i, onehot_encoded, data['text'], 256, 500,16, 1024,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nodes=[[16,'nodes_16_model.hdf5','nodes_16_acc.png', 'nodes_16_loss.png', 'nodes_16_acc.csv', 'nodes_16_loss.csv']b]\n",
    "for h,i,j,k,l,m in nodes:\n",
    "    bidir_LSTM_1_hidden_layer_lr(i,j, k, l, m,1e-5, onehot_encoded,  data['text'], 256, 500,h, 1024,1000, 1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16 nodes gave 59% validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nodes= [[32,'nodes_32_model.hdf5','nodes_32_acc.png', 'nodes_32_loss.png', 'nodes_32_acc.csv', 'nodes_32_loss.csv']]\n",
    "for h,i,j,k,l,m in nodes:\n",
    "    bidir_LSTM_1_hidden_layer_lr(i,j, k, l, m,1e-4, onehot_encoded,  data['text'], 256, 500,h, 1024,1000, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes: [[64,'nodes_64_model.hdf5','nodes_64_acc.png', 'nodes_64_loss.png', 'nodes_64_acc.csv', 'nodes_64_loss.csv'],[128,'nodes_128_model.hdf5','nodes_128_acc.png', 'nodes_128_loss.png', 'nodes_128_acc.csv', 'nodes_128_loss.csv']]\n",
    "for h,i,j,k,l,m in nodes:\n",
    "    bidir_LSTM_1_hidden_layer_lr(i,j, k, l, m,1e-5, onehot_encoded,  data['text'], 256, 500,h, 1024,1000, 1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to go for 12 hidden nodes after the previous experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg=[[1e-2,'kern_1e-2_model.hdf5','kern_reg1e-2_acc.png', 'kern_reg1e-2_loss.png', 'kern_reg1e-2_acc.csv', 'kern_reg1e-2_loss.csv'],[1e-3,'kern_1e-3_model.hdf5','kern_reg1e-3_acc.png', 'kern_reg1e-3_loss.png', 'kern_reg1e-3_acc.csv', 'kern_reg1e-3_loss.csv'], [1e-4,'kern_1e-4_model.hdf5','kern_reg1e-4_acc.png', 'kern_reg1e-4_loss.png', 'kern_reg1e-4_acc.csv', 'kern_reg1e-4_loss.csv'], [1e-5,'kern_1e-5_model.hdf5','kern_reg1e-5_acc.png', 'kern_reg1e-5_loss.png', 'kern_reg1e-5_acc.csv', 'kern_reg1e-5_loss.csv']]\n",
    "for h, i, j, k, l , m in reg:\n",
    "    padded_docs=one_hot_enc(vocab_size_val, data['text'], 500)\n",
    "    bidir_LSTM_1_hidden_layer_lr(i,j, k, l, m,1e-4, onehot_encoded, padded_docs, vocab_size_val, 256, 500,12, 1024, 1000,h)\n",
    "    #iets toevoegen waarbij ik de accuraatheid op de validatieset dan kan displayen en vergelijken over de verschillende modellen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(padded_docs, onehot_encoded, test_size=0.3, random_state=42, stratify=onehot_encoded)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)\n",
    "list_acc=[]\n",
    "for i in ['kern_1e-2_model.hdf5','kern_1e-3_model.hdf5', 'kern_1e-4_model.hdf5', 'kern_1e-5_model.hdf5']:\n",
    "    my_model = load_model(i)\n",
    "    loss, acc = my_model.evaluate(X_val, y_val)\n",
    "    print('Restored model, accuracy: {:5.2f}%'.format(100 * acc))\n",
    "    list_acc.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "reg=[1e-2, 1e-3, 1e-4, 1e-5]\n",
    "plt.xlabel('Kernel Regularizer')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(reg, list_acc)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reg=[[1e-2,'rec_1e-2_model.hdf5','rec_reg1e-2_acc.png', 'rec_reg1e-2_loss.png', 'rec_reg1e-2_acc.csv', 'rec_reg1e-2_loss.csv' ], [1e-3,'rec_1e-3_model.hdf5','rec_reg1e-3_acc.png', 'rec_reg1e-3_loss.png', 'rec_reg1e-3_acc.csv', 'rec_reg1e-3_loss.csv'],[1e-4,'rec_1e-4_model.hdf5','rec_reg1e-4_acc.png', 'rec_reg1e-4_loss.png', 'rec_reg1e-4_acc.csv', 'rec_reg1e-4_loss.csv'], [1e-5,'rec_1e-5_model.hdf5','rec_reg1e-5_acc.png', 'rec_reg1e-5_loss.png', 'rec_reg1e-5_acc.csv', 'rec_reg1e-5_loss.csv']]\n",
    "padded_docs=one_hot_enc(vocab_size_val, data['text'], 500)\n",
    "for h,i,j,k,l,m in reg:\n",
    "    bidir_LSTM_1_hidden_layer_lr(i,j, k, l, m,1e-4, onehot_encoded, padded_docs, vocab_size_val, 256, 500,12, 1024, 1000,1e-2, h) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reg=[[1e-2,'bias_1e-2_model.hdf5','bias_reg1e-2_acc.png', 'bias_reg1e-2_loss.png', 'bias_reg1e-2_acc.csv', 'bias_reg1e-2_loss.csv' ], [1e-3,'bias_1e-3_model.hdf5','bias_reg1e-3_acc.png', 'bias_reg1e-3_loss.png', 'bias_reg1e-3_acc.csv', 'bias_reg1e-3_loss.csv'],[1e-4,'bias_1e-4_model.hdf5','bias_reg1e-4_acc.png', 'bias_reg1e-4_loss.png', 'bias_reg1e-4_acc.csv', 'bias_reg1e-4_loss.csv'], [1e-5,'bias_1e-5_model.hdf5','bias_reg1e-5_acc.png', 'bias_reg1e-5_loss.png', 'bias_reg1e-5_acc.csv', 'bias_reg1e-5_loss.csv']]\n",
    "for h,i,j,k,l,m in reg:\n",
    "    bidir_LSTM_1_hidden_layer_lr(i, j, k, l, m,1e-4, onehot_encoded, data['text'], 256, 500,12, 1024, 1000,1e-2, 1e-3, h) \n",
    "    #alle regularizers staan op 1e-3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_acc=[]\n",
    "for i in['bias_1e-2_model.hdf5', 'bias_1e-3_model.hdf5', 'bias_1e-4_model.hdf5', 'bias_1e-5_model.hdf5']:\n",
    "    my_model=load_model(i)\n",
    "    loss, acc = my_model.evaluate(X_val, y_val)\n",
    "    print('Restored model, accuracy: {:5.2f}%'.format(100 * acc))\n",
    "    list_acc.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "reg=[1e-2, 1e-3, 1e-4, 1e-5]\n",
    "plt.xlabel('Kernel Regularizer')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(reg, list_acc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reg=[[1e-2,'act_1e-2_model.hdf5','act_reg1e-2_acc.png', 'act_reg1e-2_loss.png', 'act_reg1e-2_acc.csv', 'act_reg1e-2_loss.csv' ], [1e-3,'act_1e-3_model.hdf5','act_reg1e-3_acc.png', 'act_reg1e-3_loss.png', 'act_reg1e-3_acc.csv', 'act_reg1e-3_loss.csv'],[1e-4,'act_1e-4_model.hdf5','act_reg1e-4_acc.png', 'act_reg1e-4_loss.png', 'act_reg1e-4_acc.csv', 'act_reg1e-4_loss.csv'], [1e-5,'act_1e-5_model.hdf5','act_reg1e-5_acc.png', 'act_reg1e-5_loss.png', 'act_reg1e-5_acc.csv', 'act_reg1e-5_loss.csv']]\n",
    "for h,i,j,k,l,m in reg:\n",
    "    bidir_LSTM_1_hidden_layer_lr(i, j, k, l, m,1e-4, onehot_encoded, data['text'], 256, 500,12, 1024, 1000,1e-2, 1e-3,1e-5, h) \n",
    "    #alle regularizers staan op 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_acc=[]\n",
    "for i in['act_1e-2_model.hdf5', 'act_1e-3_model.hdf5', 'act_1e-4_model.hdf5', 'act_1e-5_model.hdf5']:\n",
    "    my_model=load_model(i)\n",
    "    loss, acc = my_model.evaluate(X_val, y_val)\n",
    "    print('Restored model, accuracy: {:5.2f}%'.format(100 * acc))\n",
    "    list_acc.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "reg=[1e-2, 1e-3, 1e-4, 1e-5]\n",
    "plt.xlabel('Activity Regularizer')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(reg, list_acc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reg=[[0.1,'dropout_0.1_model.hdf5','dropout_0.1_acc.png', 'dropout_0.1_loss.png', 'dropout_0.1_acc.csv', 'dropout_0.1_loss.csv' ], [0.3,'dropout_0.3_model.hdf5','dropout_0.3_acc.png', 'dropout_0.3_loss.png', 'dropout_0.3_acc.csv', 'dropout_0.3_loss.csv']]\n",
    "for h,i,j,k,l,m in reg:\n",
    "    bidir_LSTM_1_hidden_layer_lr(i, j, k, l, m,1e-4, onehot_encoded, data['text'], 256, 500,12, 1024, 1000,1e-2, 1e-3,1e-5,1e-3, h) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_acc=[]\n",
    "for i in['dropout_0.1_model.hdf5', 'act_1e-3_model.hdf5', 'dropout_0.3_model.hdf5']:\n",
    "    my_model=load_model(i)\n",
    "    loss, acc = my_model.evaluate(X_val, y_val)\n",
    "    print('Restored model, accuracy: {:5.2f}%'.format(100 * acc))\n",
    "    list_acc.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "reg=[0.1, 0.2, 0.3]\n",
    "plt.xlabel('Dropout')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(reg, list_acc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reg=[[0.1,'rec_dropout_0.1_model.hdf5','rec_dropout_0.1_acc.png', 'rec_dropout_0.1_loss.png', 'rec_dropout_0.1_acc.csv', 'rec_dropout_0.1_loss.csv' ], [0.3,'rec_dropout_0.3_model.hdf5','rec_dropout_0.3_acc.png', 'rec_dropout_0.3_loss.png', 'rec_dropout_0.3_acc.csv', 'rec_dropout_0.3_loss.csv']]\n",
    "for h,i,j,k,l,m in reg:\n",
    "    bidir_LSTM_1_hidden_layer_lr(i, j, k, l, m,1e-4, onehot_encoded, data['text'], 256, 500,12, 1024, 1000,1e-2, 1e-3,1e-5,1e-3,0.2, h) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_acc=[]\n",
    "for i in['rec_dropout_0.1_model.hdf5', 'rec_dropout_0.3_model.hdf5']:\n",
    "    my_model=load_model(i)\n",
    "    loss, acc = my_model.evaluate(X_val, y_val)\n",
    "    print('Restored model, accuracy: {:5.2f}%'.format(100 * acc))\n",
    "    list_acc.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "reg=[0.1, 0.3]\n",
    "plt.xlabel(' Recurrent Dropout')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(reg, list_acc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model=load_model('rec_dropout_0.3_model.hdf5')\n",
    "loss, acc = my_model.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=my_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth=np.argmax(y_test,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The Accuracy of the model is',metrics.accuracy_score(predictions, ground_truth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cf_mat(y_test, y_pred):\n",
    "    mat=metrics.confusion_matrix(y_test, y_pred)/len(y_test)\n",
    "    return sns.heatmap(mat, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(' The Macro F1 measure is', metrics.f1_score(ground_truth, predictions, average='macro'))\n",
    "print(' The Macro precision is',metrics.precision_score(ground_truth, predictions, average='macro'))\n",
    "print(' The Macro recall is',metrics.recall_score(ground_truth, predictions, average='macro'))\n",
    "        \n",
    "print('The Accuracy of the model is',metrics.accuracy_score(ground_truth, predictions))\n",
    "print('The Spearman correlation of the model is ', stats.spearmanr(ground_truth, predictions))\n",
    "print('The Kendall tau of the model is ', stats.kendalltau(ground_truth, predictions))\n",
    "print('The confusion matrix looks as follows', cf_mat(ground_truth, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
